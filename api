from flask import Flask, request, jsonify, Response
from flask_cors import CORS
import requests
import json
import time
import os

app = Flask(__name__)
CORS(app)

NVIDIA_API_KEY = os.environ.get('NVIDIA_API_KEY', '')
NVIDIA_BASE_URL = 'https://integrate.api.nvidia.com/v1'

# Map OpenAI model names to NVIDIA NIM models
MODEL_MAPPING = {
    "gpt-3.5-turbo": "meta/llama-3.1-8b-instruct",
    "gpt-4": "meta/llama-3.1-70b-instruct",
    "gpt-4-turbo": "meta/llama-3.1-405b-instruct",
    "gpt-4o": "deepseek-ai/deepseek-v3.1",
    "deepseek": "deepseek-ai/deepseek-r1"
}

@app.route('/v1/chat/completions', methods=['POST', 'OPTIONS'])
def chat_completions():
    if request.method == 'OPTIONS':
        return '', 204
        
    if not NVIDIA_API_KEY:
        return jsonify({"error": "NVIDIA_API_KEY not configured"}), 500
        
    try:
        data = request.json
        openai_model = data.get('model', 'gpt-3.5-turbo')
        nvidia_model = MODEL_MAPPING.get(openai_model, "meta/llama-3.1-8b-instruct")
        
        nvidia_payload = {
            "model": nvidia_model,
            "messages": data.get('messages', []),
            "temperature": data.get('temperature', 0.7),
            "top_p": data.get('top_p', 1.0),
            "max_tokens": data.get('max_tokens', 1024),
            "stream": data.get('stream', False)
        }
        
        headers = {
            "Authorization": f"Bearer {NVIDIA_API_KEY}",
            "Content-Type": "application/json"
        }
        
        nvidia_response = requests.post(
            f"{NVIDIA_BASE_URL}/chat/completions",
            headers=headers,
            json=nvidia_payload,
            stream=nvidia_payload['stream'],
            timeout=60
        )
        
        if nvidia_payload['stream']:
            def generate():
                for line in nvidia_response.iter_lines():
                    if line:
                        yield line.decode('utf-8') + '\n'
            
            return Response(generate(), mimetype='text/event-stream')
        else:
            nvidia_data = nvidia_response.json()
            
            openai_response = {
                "id": nvidia_data.get("id", f"chatcmpl-{int(time.time())}"),
                "object": "chat.completion",
                "created": int(time.time()),
                "model": openai_model,
                "choices": [{
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": nvidia_data.get("choices", [{}])[0].get("message", {}).get("content", "")
                    },
                    "finish_reason": nvidia_data.get("choices", [{}])[0].get("finish_reason", "stop")
                }],
                "usage": nvidia_data.get("usage", {
                    "prompt_tokens": 0,
                    "completion_tokens": 0,
                    "total_tokens": 0
                })
            }
            
            return jsonify(openai_response)
            
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/v1/models', methods=['GET', 'OPTIONS'])
def list_models():
    if request.method == 'OPTIONS':
        return '', 204
        
    models = [
        {
            "id": model_name,
            "object": "model",
            "created": int(time.time()),
            "owned_by": "nvidia"
        }
        for model_name in MODEL_MAPPING.keys()
    ]
    
    return jsonify({"object": "list", "data": models})

@app.route('/', methods=['GET'])
@app.route('/health', methods=['GET'])
def health():
    return jsonify({
        "status": "healthy",
        "service": "NVIDIA NIM Proxy",
        "endpoints": ["/v1/chat/completions", "/v1/models"]
    })
